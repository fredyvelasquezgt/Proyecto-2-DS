---
title: "Proyecto 2. Resultados Parciales y Visualizaciones Estáticas"
author: "Javier Valle, Angel Higueros, Mariana David, Mario De Leon"
date: "2022-10-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Algoritmos y modelos seleccionados

Naive Bayes porque es el más simple en cuanto a clasificación de texto. Además de su fácil implementación. También porque estamos familiarizados con el teorema de Naive Bayes.

## Construcción de modelos

Para la elaboracion del modelo con el algoritmo Naive Bayes se llevaron a cabo los siguientes pasos:
1. Creacion de Corpus
2. Preprocesamiento de Corpus
3. Creacion de matriz
4. Creacion de datos de entrenamiento y prueba

```{r message=FALSE, warning=FALSE}
#Import libraries
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer) 
library(e1071)         #For Naive Bayes
library(caret)         #For the Confusion Matrix

library(gmodels) #provides CrossTable() function for comparison

db<-read.csv('train.csv')

db<-db[,c(3,5)]
colnames(db)<-c('Msg','Tag')

db$Tag<-factor(db$Tag)
# creating our corpus
text_corpus <- VCorpus(VectorSource(db$Msg))

# Viewing the content of more than one texts using lapply() function
lapply(text_corpus[1:5], as.character) 

cleanCorpus <- tm_map(text_corpus, content_transformer(tolower)) # lowercase all texts
cleanCorpus <- tm_map(cleanCorpus, removeNumbers) # remove all numbers
cleanCorpus <- tm_map(cleanCorpus, removeWords, stopwords('english')) # remove all common words such as to, but and etc.
cleanCorpus <- tm_map(cleanCorpus, removePunctuation) # remove all punctuation
cleanCorpus <- tm_map(cleanCorpus, stripWhitespace) # remove all whitespace

text_dtm <- DocumentTermMatrix(cleanCorpus)


# Creating train and test portions 
porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(text_dtm),nrow(text_dtm)*porcentaje)

train <- text_dtm[corte,] # 70% for training
test <- text_dtm[-corte, ] # 30% for testing
train_type <- db[corte, ]$Tag
test_type <- db[-corte, ]$Tag


#training portion
tbl_train <- prop.table(table(train_type))

#testing portion
tbl_test <- prop.table(table(test_type))


freq_words <- findFreqTerms(train, 5) 
str(freq_words)

# Selecting only the frequent words from the train and test datasets
freq_words_train <- train[ , freq_words]
freq_words_test <- test[ , freq_words]


# creating a function for conversion
convert <- function(x) {x <- ifelse(x > 0, "y", "n")} 
train <- apply(freq_words_train, MARGIN = 2, convert)
test <- apply(freq_words_test, MARGIN = 2, convert)


# Creating a Naive Bayes classifier
sms_classifier <- naiveBayes(train, train_type)
# Making prediction & evaluation with the classifier
test_prediction <- predict(sms_classifier, test)

CrossTable(test_prediction, test_type, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))

#Modelo 2
sms_classifier_improved <- naiveBayes(train, train_type, laplace = 1)
test_prediction_improved <- predict(sms_classifier_improved, test)

CrossTable(test_prediction_improved, test_type, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))


```



## Discusión

Ambos modelos son muy similares en cuanto a los resultados, tienen la misma precisión a la hora de predecir excepto al clasificar argumentos ineficaces, el primer modelo arroja una precisión de 35% y el segundo un 34%, sigue siendo una precisión muy similar. Para argumentos adecuados y efectivos se obtuvo precisiones de 65% y 60% en ambos modelos. Se comprueba que el algoritmo de Naive Bayes es eficaz en la aplicación de clasificación de textos sin necesidad de muchos recursos.

Los NBC escalan muy bien, lo que significa que podemos agregar muchas más funciones y el algoritmo seguirá siendo rápido y confiable. Incluso en el caso de que los NBC no fueran adecuados para el problema que se está tratando de resolver, podrían ser útiles como referencia.

## Visualizaciones estáticas

```{r include=FALSE}
spamText <- subset(db, Tag == "Adequate") 

hamText <- subset(db, Tag =="Ineffective")

amText <- subset(db, Tag =="Effective")
```

Frecuencia de las palabras en los argumentos que son clasificados como "Adequate" representada en una nube de palabras.

```{r message=FALSE, warning=FALSE}
wordcloud(spamText$Msg, max.words = 50, scale = c(5, 0.3),random.order = FALSE, rot.per = 0.15, colors = brewer.pal(8, "Dark2"))
```

Frecuencia de las palabras en los argumentos que son clasificados como "Effective" representada en una nube de palabras.

```{r message=FALSE, warning=FALSE}
wordcloud(amText$Msg, max.words = 50, scale = c(5, 0.3),random.order = FALSE, rot.per = 0.15, colors = brewer.pal(8, "Dark2"))
```

Frecuencia de las palabras en los argumentos que son clasificados como "Ineffective" representada en una nube de palabras.

```{r message=FALSE, warning=FALSE}
wordcloud(hamText$Msg, max.words = 50, scale = c(5, 0.3),random.order = FALSE, rot.per = 0.15, colors = brewer.pal(8, "Dark2"))
```
