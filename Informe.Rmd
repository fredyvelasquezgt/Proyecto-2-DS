---
title: "Proyecto 2"
author: "Angel Higueros, Mariana David, Javier Valle, Fredy Velasquez"
date: "2023-09-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



### Descripcion de los datos

```{r Analisis Exploratorio}

db<- read.csv('train.csv')


```


#### Representación gráfica de los datos

```{r}
plot(x = db$discourse_id)
plot(x = db$essay_id)
```

### Analisis Exploratorio

La base de datos cuenta con `r nrow(db)` filas y `r ncol(db)` columnas


```{r message=FALSE, warning=FALSE}
# Librerias necesarias

library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library(dplyr)
# Limpiamos el texto

```
#### 1. ¿Cuál es el tipo de discurso predominante?

```{r}

disType <- db %>% 
  group_by(db$discourse_type) %>% 
  tally()

colnames(disType)[1]<-'Tipo'
colnames(disType)[2]<-'Cantidad'

ggplot(data=disType, aes(x=reorder(Tipo,Cantidad), y=Cantidad,fill=Tipo)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Cantidad), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  labs(title="Predominancia de un discurso",x='Tipo de discurso', y="Cantidad")+
  theme(legend.position="none")
```



#### Cantidad de discursos categorizados como ineficaz, adecuado y eficaz

```{r}
cantType <- db %>% 
  group_by(db$discourse_effectiveness) %>% 
  tally()

colnames(cantType)[1]<-'Tipo'
colnames(cantType)[2]<-'Cantidad'

ggplot(data=cantType, aes(x=reorder(Tipo,Cantidad), y=Cantidad,fill=Tipo)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Cantidad), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  labs(title="Efectividad de los discursos",x='Efectividad', y="Cantidad")+
  theme(legend.position="none")

```
<br />
Como se observa, los 3 tipos de efectividad no se encuentran balanceados.

#### Analisis del los discursos

##### Analisis del discurso sin limpieza
```{R warning=FALSE}

wordcloud(words = db$discourse_text, 
          max.words=80, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))



```


```{r warning=FALSE}

TextDoc <- Corpus(VectorSource(db$discourse_text))
#Replacing "/", "@" and "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "@")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")
# Convert the text to lower case
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
# Remove numbers
TextDoc <- tm_map(TextDoc, removeNumbers)
# Remove english common stopwords
TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
# Remove your own stop word
# specify your custom stopwords as a character vector
TextDoc <- tm_map(TextDoc, removeWords, c("like", "just", "get",'will','new','now','via','dont','one','can')) 
# Remove punctuations
TextDoc <- tm_map(TextDoc, removePunctuation)
# Eliminate extra white spaces
TextDoc <- tm_map(TextDoc, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc <- tm_map(TextDoc, stemDocument)

TextDoc_dtm <- TermDocumentMatrix(TextDoc)
dtm_m <- as.matrix(TextDoc_dtm)
 # Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
# Display the top 5 most frequent words
head(dtm_d)
# Plot the most frequent words
barplot(dtm_d[1:5,]$freq, las = 2, names.arg = dtm_d[1:5,]$word,
        col ="lightgreen", main ="Top 5 most frequent words",
        ylab = "Word frequencies")
set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

##### Analisis de sentimiento en los discursos

```{r warning=FALSE}

syuzhet_vector <- get_sentiment(db$discourse_text, method="syuzhet")
# see the first row of the vector
head(syuzhet_vector)
# see summary statistics of the vector
summary(syuzhet_vector)

# bing
bing_vector <- get_sentiment(db$discourse_text, method="bing")
head(bing_vector)
summary(bing_vector)
#affin
afinn_vector <- get_sentiment(db$discourse_text, method="afinn")
head(afinn_vector)
summary(afinn_vector)

#compare the first row of each vector using sign function
rbind(
  sign(head(syuzhet_vector)),
  sign(head(bing_vector)),
  sign(head(afinn_vector))
)

d<-get_nrc_sentiment(db$discourse_text)
# head(d,10) - to see top 10 lines of the get_nrc_sentiment dataframe
head (d,10)
db$Enojo<- d$anger
db$Anticipacion<- d$anticipation
db$Disgusto<- d$disgust
db$Miedo<- d$fear
db$Felicidad<- d$joy
db$Tristeza<- d$sadness
db$Sorpresa<- d$surprise
db$Verdad<- d$trust
db$Negativo<- d$negative
db$Positivo<- d$positive

# transponer
td<-data.frame(t(d))

# La función rowSums calcula la suma de columnas a través de las filas para cada nivel de una variable de agrupacion
td_new <- data.frame(rowSums(td[2:253]))

# Transformación y limpieza
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]

# Gráfica Uno - cuenta de palabras asociadas con cada sentimiento
quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Sentimientos de la encuesta")

# Gráfica Dos - cuenta de palabras asociadas con cada sentimiento, expresado como porcentaje
barplot(
  sort(colSums(prop.table(d[, 1:8]))), 
  horiz = TRUE, 
  cex.names = 0.7, 
  las = 1, 
  main = "Emociones en el Texto", xlab="Porcentaje"
)

```

```{r}
library(dplyr)

ineficiente <- db %>% filter(discourse_effectiveness == "Ineffective")
summary(ineficiente)

Efectivo <- db %>% filter(discourse_effectiveness == "Effective")
summary(Efectivo)

Adecuado <- db %>% filter(discourse_effectiveness == "Adequate")
summary(Adecuado)

```


```{r}
library(dplyr)

# Función auxiliar para calcular medias
obtener_media <- function(categoria, columna) {
  mean(categoria[[columna]])
}

resumen <- data.frame(
  Categoria = c("Ineficiente", "Adecuado", "Eficiente"),
  Enojo = c(obtener_media(ineficiente, "Enojo"), obtener_media(Adecuado, "Enojo"), obtener_media(Efectivo, "Enojo")),
  Anticipacion = c(obtener_media(ineficiente, "Anticipacion"), obtener_media(Adecuado, "Anticipacion"), obtener_media(Efectivo, "Anticipacion")),
  Disgusto = c(obtener_media(ineficiente, "Disgusto"), obtener_media(Adecuado, "Disgusto"), obtener_media(Efectivo, "Disgusto")),
  Miedo = c(obtener_media(ineficiente, "Miedo"), obtener_media(Adecuado, "Miedo"), obtener_media(Efectivo, "Miedo")),
  Felicidad = c(obtener_media(ineficiente, "Felicidad"), obtener_media(Adecuado, "Felicidad"), obtener_media(Efectivo, "Felicidad")),
  Tristeza = c(obtener_media(ineficiente, "Tristeza"), obtener_media(Adecuado, "Tristeza"), obtener_media(Efectivo, "Tristeza")),
  Sorpresa = c(obtener_media(ineficiente, "Sorpresa"), obtener_media(Adecuado, "Sorpresa"), obtener_media(Efectivo, "Sorpresa")),
  Verdad = c(obtener_media(ineficiente, "Verdad"), obtener_media(Adecuado, "Verdad"), obtener_media(Efectivo, "Verdad")),
  Negativo = c(obtener_media(ineficiente, "Negativo"), obtener_media(Adecuado, "Negativo"), obtener_media(Efectivo, "Negativo")),
  Positivo = c(obtener_media(ineficiente, "Positivo"), obtener_media(Adecuado, "Positivo"), obtener_media(Efectivo, "Positivo"))
)

resumen

```

##### Cantidad de palabras

```{r}
library(tidyverse)
library(stringr)

# Leer los datos
db <- read.csv("train.csv")

# Calcular la cantidad de palabras para cada discurso
db <- db %>%
  mutate(CantidadPalabras = str_count(discourse_text, '\\w+'))

# Agrupar y resumir los datos por efectividad del discurso
resumen <- db %>%
  group_by(discourse_effectiveness) %>%
  summarize(Promedio = mean(CantidadPalabras, na.rm = TRUE)) %>%
  filter(discourse_effectiveness %in% c("Ineffective", "Effective", "Adequate")) %>%
  rename(Categoria = discourse_effectiveness)

# Crear el gráfico
ggplot(data=resumen, aes(x=reorder(Categoria, Promedio), y=Promedio, fill=Categoria)) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_text(aes(label=Promedio), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5) +
  labs(title="Promedio de palabras por categoría", x='Categoría', y="Promedio") +
  theme(legend.position="none")
```

### Hallazgos y conclusiones

